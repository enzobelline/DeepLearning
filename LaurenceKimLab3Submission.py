# -*- coding: utf-8 -*-
"""lab3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jmDBlVM32Ekp40fD7vyd0kGQqmOBF0bM
"""

# Commented out IPython magic to ensure Python compatibility.
import time
import numpy as np
import pandas as pd

from keras.datasets import mnist

from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# %matplotlib inline

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns

from autograd import elementwise_grad as grad

"""# 0. Using ChatGPT to help you understand optimizers

Recently I had an interview question for Deep Learning candidates, and they were not able to answer these questions.

Write one paragraph with the help of ChatGPT (or equivalent) explaining each one of the following optimizers, and in the last paragraph, reviewed by the notes from the lab last week, write a comparison of the advantages and disadvantages of each one.  Please note that ChatGPT may hallucinate, so you need to double-check what ChatGPT answers.

- Stochastic Gradient Descent
- SGD with momentum
- RMSProp
- Adadelta
- Adam
- Adam with warmup

Stochastic Gradient Descent (SGD) is a fundamental optimization algorithm used in machine learning and deep learning. It updates model parameters by computing the gradient of the loss function with respect to a small batch of training data samples and making incremental adjustments to minimize the loss.

SGD with momentum enhances the basic SGD algorithm by adding momentum to the update process. It accumulates a moving average of past gradients and uses this momentum term to smooth out the parameter updates, helping to overcome oscillations and speed up convergence.

RMSProp, short for Root Mean Square Propagation, is another optimization algorithm designed to tackle the problem of slow convergence. It maintains a moving average of the squared gradients and uses this information to adapt the learning rates for each parameter individually, allowing for faster convergence on different dimensions.

Adadelta is a variant of RMSProp that further improves convergence by dynamically adjusting the learning rates without the need for a predefined global learning rate. It relies on a running average of past gradients and adapts learning rates based on the magnitude of past updates.

Adam, which stands for Adaptive Moment Estimation, is a popular optimization algorithm that combines ideas from both momentum and RMSProp. It maintains moving averages of both the first-order (gradients) and second-order (squared gradients) moments, allowing for adaptive learning rates and efficient convergence.

Adam with warmup is an extension of the Adam optimizer that incorporates a warmup phase at the beginning of training. During this phase, the learning rate is gradually increased to help the model stabilize and avoid divergence at the start of training.

Now, let's compare the advantages and disadvantages of these optimizers based on the notes from the lab last week. Stochastic Gradient Descent (SGD) is computationally efficient but may suffer from slow convergence and oscillations. SGD with momentum helps alleviate these issues by adding momentum, but it might require fine-tuning of the momentum parameter. RMSProp and Adadelta address the learning rate adaptability problem, but Adadelta may be sensitive to its hyperparameters. Adam combines the benefits of both momentum and RMSProp and is widely used, but it might require more memory and computation. Adam with warmup is effective in stabilizing training but introduces an additional hyperparameter to tune. The choice of optimizer should depend on the specific problem and empirical experimentation, considering factors like the dataset size, model architecture, and available computational resources.

# 1. Optimizers

In this lab, we will implement some optimizers and see how they behave.

## 1.1. Solving $A x = b$

if Matrix A is not square then we need to multiply the

$A^T A x = A^T b$

$x = (A^TA)^-1 A^T b$
"""

A = np.array([[2,1,3] , [2,6,8] , [6,8,18]]).astype(np.float32)
b = np.array([[1],[3],[5]]).astype(np.float32)
alpha = 0.1
beta1 = 0.1
beta2 = 0.1

print(np.linalg.inv(A), b)
np.dot(np.linalg.inv(A), b)

# this is the optimization function.
# we want to obtain x so that (Ax - b)**2 is minimized.

def F(x):
  return np.dot(A,x) - b

# definition of loss function (MSE of F(x))
def L(x):
  # (1,3) x (3,1) -=>(1,1)
  return np.sum((np.dot(A, x) - b) ** 2)

def g(x):
    return 2 * np.dot(A.T, np.dot(A, x) - b)

# plot loss over time until it converges

def GD(x, alpha, verbose=False):
  """Implementation of gradient descent loop."""
  i = 0
  history = []

  while True:
    x = x - alpha * g(x).T
    loss = L(x)
    history.append(loss)
    if verbose:
      print(i, loss, x.flatten())
    i += 1
    if np.all(loss < 1e-7)or np.all(loss>1e100):
      break
    if np.isnan(loss).any():
      print("Optimization terminated due to NaN loss.")
      break

  return x, history

def Momentum(x, alpha, beta, verbose=False):
    i = 0
    history = []
    prev_velocity = np.zeros_like(x)

    while True:
        gradient = g(x)
        velocity = beta * prev_velocity + alpha * gradient
        x = x - velocity.T
        loss = L(x)
        history.append(loss)

        if verbose:
            print(i, loss, x.flatten())

        i += 1
        if np.all(loss < 1e-7) or np.all(loss>1e1000):
          break
        if np.isnan(loss).any():
          print("Optimization terminated due to NaN loss.")
          break
    return x, history

def Adadelta(x, rho, epsilon, verbose=False):
    i = 0
    history = []
    E_g_sq = np.zeros_like(x)
    E_delta_x_sq = np.zeros_like(x)

    while True:
        gradient = g(x)
        E_g_sq = rho * E_g_sq + (1 - rho) * gradient**2
        delta_x = -np.sqrt(E_delta_x_sq + epsilon) * gradient / np.sqrt(E_g_sq + epsilon)
        x = x + delta_x.T
        E_delta_x_sq = rho * E_delta_x_sq + (1 - rho) * delta_x**2
        loss = L(x)
        history.append(loss)

        if verbose:
            print(i, loss, x.flatten())

        i += 1
        if np.all(loss < 1e-7)or np.all(loss>1e5):
            break
        if np.isnan(loss).any():
          print("Optimization terminated due to NaN loss.")
          break

    return x, history


def Adam(x, alpha, beta1, beta2, epsilon, verbose=False):
    i = 0
    history = []
    m = np.zeros_like(x)
    v = np.zeros_like(x)
    t = 0

    while True:
        t += 1
        gradient = g(x)
        m = beta1 * m + (1 - beta1) * gradient
        v = beta2 * v + (1 - beta2) * gradient**2
        m_hat = m / (1 - beta1**t)
        v_hat = v / (1 - beta2**t)
        delta_x = -alpha * m_hat / (np.sqrt(v_hat) + epsilon)
        x = x + delta_x.T
        loss = L(x)
        history.append(loss)

        if verbose:
            print(i, loss, x.flatten())
        i += 1
        if np.all(loss < 1e-7)or np.all(loss>1e10):
          break
        if np.isnan(loss).any():
          print("Optimization terminated due to NaN loss.")
          break
    return x, history

def AdamWithWarmup(x, ramp_n, alpha, beta1, beta2, epsilon, verbose=False):
    i = 0
    history = []
    m = np.zeros_like(x)
    v = np.zeros_like(x)
    t = 0

    while True:
        t += 1
        gradient = g(x)

        # Adjust the learning rate during warmup
        if i < ramp_n:
            lr = (i / ramp_n) * alpha
        else:
            lr = alpha

        m = beta1 * m + (1 - beta1) * gradient
        v = beta2 * v + (1 - beta2) * gradient**2
        m_hat = m / (1 - beta1**t)
        v_hat = v / (1 - beta2**t)
        delta_x = -lr * m_hat / (np.sqrt(v_hat) + epsilon)
        x = x + delta_x.T
        loss = L(x)
        history.append(loss)

        if verbose:
            print(i, loss, x.flatten())

        i += 1
        if np.all(loss < 1e-7) or np.all(loss>1e100):
          break
        if np.isnan(loss).any():
          print("Optimization terminated due to NaN loss.")
          break

    return x, history

x1 = np.random.uniform(-1.0,1.0,size=(3,1))
x2 = np.copy(x1)
x3 = np.copy(x1)
x4 = np.copy(x1)
x5 = np.copy(x1)
print(x1)

alpha=0.01
beta=0.01
epsilon=0.001
beta1=0.01
beta2=0.01
rho = 0.01
ramp_n = 1

x1, history_gd = GD(x1, alpha, verbose=True)
print(len(history_gd))

x2, history_mo = Momentum(x2, alpha,beta, verbose=True)

x3, history_add = Adadelta(x3, rho, epsilon, verbose=True)

x4, history_ada = Adam(x4, alpha, beta1, beta2, epsilon, verbose=True)

x5, history_adawu = AdamWithWarmup(x5, ramp_n, alpha, beta1, beta2, epsilon, verbose=True)

plt.plot(history_gd, label='SGD')
plt.plot(history_mo, label='Momentum')
plt.plot(history_add, label='Adadelta')
plt.plot(history_ada, label='Adam')
plt.plot(history_adawu, label='Adam with Warmup')
plt.legend()
plt.show()

# For Ax = b, the solution is (A**-1 * b).T
print("Solution is: ", np.dot(np.linalg.inv(A),b).T)

"""## 1.2. Function ${(1-x_0)}^2 + 100 {(x_1 - x_0^2)}^2$

### [ Rosenbrock function ]
"""

def F(x):
  return np.power(1-x[0],2) + 100.0*np.power(x[1] - np.power(x[0],2),2)

# definition of loss function (F(x)) - let's see when this function is 0
def L(x):
  return F(x)

# definition of gradient
def g(x):
  return np.array([
    -(1-x[0]) - 100.0*4*x[0]*(x[1] - np.power(x[0],2)),
    100.0*2*(x[1] - np.power(x[0],2))
  ])

x1 = np.random.uniform(-1.0,1.0,size=(2,1))
x2 = np.copy(x1)
x3 = np.copy(x1)
x4 = np.copy(x1)
x5 = np.copy(x1)


alpha=0.01
beta=0.001
epsilon=0.01
beta1=0.01
beta2=0.01
rho = 0.01
ramp_n = 1

x1, history_gd = GD(x1, alpha, verbose=True)

x2, history_mo = Momentum(x2, alpha,beta, verbose=True)

x3, history_add = Adadelta(x3, rho, epsilon, verbose=True)

x4, history_ada = Adam(x4, alpha, beta1, beta2, epsilon, verbose=True)

x5, history_adawu = AdamWithWarmup(x5, ramp_n, alpha, beta1, beta2, epsilon, verbose=True)

plt.plot(history_gd, label='SGD')
plt.plot(history_mo, label='Momentum')
plt.plot(history_add, label='Adadelta')
plt.plot(history_ada, label='Adam')
plt.plot(history_adawu, label='Adam with Warmup')
plt.legend()
plt.show()

"""## 1.3. Deep Learning Package From Lab2

Using the package you created in lab2, define a network and train the loss functions specified before. Plot accuracy of models.
"""

import numpy as np

from keras.datasets import mnist
from keras.utils import to_categorical

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(x_train.shape[0], 784).astype(np.float32)
x_test = x_test.reshape(x_test.shape[0], 784).astype(np.float32)

y_train = to_categorical(y_train, 10).astype(np.float32)
y_test = to_categorical(y_test, 10).astype(np.float32)

print(x_train.shape, y_train.shape)

def relu(x):
  """Computes relu of function."""
  return x * (x >= 0)


def sigmoid(x):
  """Computes sigmoid of function."""
  return 1 / (1 + np.exp(-x))

def linear(x):
  """Return linear function of itself."""
  return x

def d_linear(x):
    return np.ones_like(x)

def d_sigmoid(x):
    return sigmoid(x) * (1 - sigmoid(x))

def d_relu(x):
    return (x >= 0).astype(np.float32)

activations = {
    "linear": linear,
    "relu": relu,
    "sigmoid": sigmoid
}

d_activations = {
    "linear": d_linear,
    "relu": d_relu,
    "sigmoid": d_sigmoid
}

def initialize_weights(shapes, outputs):
  """Initializes weights of model according to shape.
     Args:
       shapes = [784, 300, 10]
       outputs = ["linear", "sigmoid"]

     returns:
       model with uniform random weights [-1,+1], zero bias and output function
       [
        [random(784, 300), zeros(300), "linear"]
        [random(300, 10), zeros(10), "sigmoid"]
       ]

  """
  weights = []
  for i in range(len(shapes) - 1):
      weight_matrix = np.random.uniform(-1, 1, (shapes[i], shapes[i+1]))
      bias_vector = np.zeros((1, shapes[i+1]))
      layer = [weight_matrix, bias_vector, outputs[i]]
      weights.append(layer)
  return weights

# Example usage:
shapes = [784, 300, 10]
outputs = ["linear", "sigmoid"]
dweights = initialize_weights(shapes, outputs)
print(len(dweights))

def forward(x, model):
    """Performs forward pass of training step.

     Args:
       x: input tensor of shape (B, N0)
       model: list of model weights (see initialize weights)
     Returns:
       List containing dictionary { "y": y, "z": z } for each layer of network.
       [{"y": y1, "z": z1}, {"y": y2, "z": z2}]
    """
    result = []
    # for idx, layer in enumerate(model):
    for layer in model:
      # layer = [ w[i], b[i], 'relu']
      z = np.dot(x, layer[0]) + layer[1]  # (x*wn) + (Bn)
      if layer[2] == 'relu':
          y = relu(x)
      if layer[2] == 'sigmoid':
          y = sigmoid(x)
      if layer[2] == 'linear':
          y = linear(x)
      # result.append({f'y{idx+1}': y, f'z{idx+1}': z})
      result.append({"y": y, "z": z})

    for layer in result:
        y_shape = layer['y'].shape
        z_shape = layer['z'].shape
        print(f"Shape of 'y': {y_shape}, Shape of 'z': {z_shape}")
    return result

def predict(x, model):
  """Predicts the output of a model.

     Args:
       x: input tensor of shape (B, Ni)
       model: list of model weights (see initialize weights)
     Returns:
       Prediction of model, with the same shape as the labeled data (B, No).
  """
  fwd = forward(x, model)
  return fwd[-1]["y"]

def backward(y, x, model, loss):
  """Computes backward step of training.
     Args:
       y: labeled data of size (B, No)
       x: input tensor of shape (B, Ni)
       model: list of model weights (see initialize weights)
       loss: one of ("mse", "binary_crossentropy")
     Returns:
       tuple with loss evaluation of (y, predict(x)) and list of dictionary
       containing { "dw": dw, "db": db } for each layer of network. Remember
       that shape of dw for each layer should be equal to shape of weight for
       the same layer.
       [{"dw": dw1, "db": db1}, {"dw": dw2, "db": db2}]
  """
  weights = []
  y = y.reshape(x[-1]["y"].shape)

  if loss == "mse":
    loss_eval = mse(y, x[-1]["y"])
    dY = x[-1]["y"] - y
  else:
    loss_eval = binary_crossentropy(y, x[-1]["y"])
    dY = -((y / x[-1]["y"]) - np.divide(1-y, 1-x[-1]["y"]))

  for i, model in reversed(list(enumerate(model))):
    new_dY = dY
    old_y = x[i]["y"]

    if model[2] == "linear":
      # Linear
      dZ = new_dY
    elif model[2] == "relu":
      # Relu
      copy = x[i + 1]["z"]
      copy[copy <= 0] = 0
      copy[copy > 0] = 1
      dZ = copy
    else:
      # Sigmoid
      dZ = sigmoid(x[i + 1]["z"]) * (1 - sigmoid(x[i + 1]["z"]))

    dW = np.dot(old_y.T, dZ)/(y.shape[0])
    dB = np.sum(dZ, axis=0, keepdims=True)/(y.shape[0])
    old_dY = np.dot(dZ, model[0].T)

    weights.insert(0, {"dw": dW, "db" :dB})

  return (loss_eval, weights)

def update(weights, dweights, alpha):
  """Gradient descent for weights and biases."""
  for i in range(len(weights)):
    weights[i][0] += - alpha * dweights[i]["dw"]
    weights[i][1] += - alpha * dweights[i]["db"]

def mse(y, p):
  """Computes Mean-Square Error between y and p.
     Args:
       y: labeled data of size (B, No)
       p: predicted label of size (B, No)
     Returns:
       MSE of y-p
  """
  assert p.shape == y.shape
  return np.mean((y - p)**2)

def binary_crossentropy(y, p):
    """Computes binary crossentropy between y and p.
       Args:
         y: labeled data of size (B, No)
         p: predicted label of size (B, No)
       Returns:
         BCE of (y, p) = mean(sum(-y * log(p) - (1-y) * log(1-p)))
    """
    epsilon = 1e-15
    p = np.clip(p, epsilon, 1 - epsilon)
    bce = - (y * np.log(p) + (1 - y) * np.log(1 - p))
    return np.mean(np.sum(bce, axis=1))

def load_data():
  (x_train, y_train), (x_test, y_test) = mnist.load_data()

  x_train = x_train.reshape(x_train.shape[0], 784).astype(np.float32)
  x_test = x_test.reshape(x_test.shape[0], 784).astype(np.float32)

  y_train = to_categorical(y_train, 10).astype(np.float32)
  y_test = to_categorical(y_test, 10).astype(np.float32)

  print(x_train.shape, y_train.shape)

def check_data_preprocessing(x_train, y_train, x_test, y_test):
    # Check the shapes of input data
    print("Shapes of input data:")
    print(f"x_train shape: {x_train.shape}")
    print(f"y_train shape: {y_train.shape}")
    print(f"x_test shape: {x_test.shape}")
    print(f"y_test shape: {y_test.shape}")

    # Check for any NaN or missing values in the data
    print("\nChecking for NaN or missing values:")
    if np.isnan(x_train).any() or np.isnan(y_train).any() or np.isnan(x_test).any() or np.isnan(y_test).any():
        print("Warning: Data contains NaN or missing values.")
    else:
        print("   Data does not contain NaN or missing values.")

    # Check data normalization (mean should be close to 0, standard deviation close to 1)
    print("\nChecking data normalization:")
    print(f"x_train mean: {np.mean(x_train)}")
    print(f"x_train std: {np.std(x_train)}")
    print(f"x_test mean: {np.mean(x_test)}")
    print(f"x_test std: {np.std(x_test)}")

def train_network():

  (x_train, y_train), (x_test, y_test) = load_data();

  # linear network
  # plot training and test loss over time in jupyter notebook
  losses = [];

  shapes = [x_train.shape[1], 1];
  outputs = ["linear"];
  model = initialize_weights(shapes, outputs);
  fwd_results = forward(x_train, model);
  print(len(fwd_results))
  # what's the alpha you should use?

  alpha = 0.4;

  for i in range(300):
    fwd_results = forward(x_train, model);
    loss, dweights = backward(y_train, fwd_results, model, "mse");
    update(model, dweights, alpha);
    losses.append(loss);


  # Test
  ftest = forward(x_test, model)
  test_loss = backward(y_test, ftest, model, "mse")


  # Plot
  fig, ax = plt.subplots()
  time = np.arange(0, 300, 1)
  ax.plot(time, losses)
  plt.axhline(y=test_loss[0], color='red')
  plt.title("Loss Graph")
  plt.ylabel("MSE")
  plt.xlabel("Epochs")
  plt.legend(["Train Loss", "Test Loss"])



train_network();

plt.plot(history_gd, label='SGD')
plt.plot(history_mo, label='Momentum')
plt.plot(history_add, label='Adadelta')
plt.plot(history_ada, label='Adam')
plt.plot(history_adawu, label='Adam with Warmup')
plt.legend()
plt.show()

"""# 2. Data Visualization

You should look at https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b, which contains a very nice introduction into visualizing datasets using PCA
and tSNE.
"""

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train.shape, y_train.shape

x_train = x_train / 255.0

"""To create a permutation of the inputs, we can just permute the indexes."""

indexes = x_train.shape[0]
indexes = np.random.permutation(indexes)
indexes

x_train = x_train[indexes]
y_train = y_train[indexes]

plt.gray()
fig = plt.figure( figsize=(16,7) )
for i in range(0,15):
    x = x_train[i]
    y = y_train[i]
    ax = fig.add_subplot(3,5,i+1, title="Digit: {}".format(str(i)))
    ax.matshow(x)
plt.show()

# we will just use the first 10000 samples
x_train_flatten = x_train.reshape(x_train.shape[0], np.prod(x_train.shape[1:]))
y_train_flatten = y_train.reshape(y_train.shape[0])
#x_train_flatten = x_train_flatten[0:1000]
#y_train_flatten = y_train_flatten[0:1000]
pca = PCA(n_components=3)
pca_result = pca.fit_transform(x_train_flatten)

fig = plt.figure(figsize=(16,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(
    xs=pca_result[:,0],
    ys=pca_result[:,1],
    zs=pca_result[:,2],
    c=y_train_flatten,
    cmap='tab10'
)
ax.set_xlabel('pca-one')
ax.set_ylabel('pca-two')
ax.set_zlabel('pca-three')
plt.show()

# tSNE is very expensive to compute. Let's use only 3000 samples
x_train_flatten = x_train_flatten[0:3000]
y_train_flatten = y_train_flatten[0:3000]
time_start = time.time()
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(x_train_flatten)
print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))

data = {"x{}".format(i): x_train_flatten[:, i] for i in range(x_train_flatten.shape[1])}
data["y"] = y_train_flatten
df = pd.DataFrame(data)

df

plt.figure(figsize=(16,10))
sns.scatterplot(
    x=tsne_results[:,0], y=tsne_results[:,1],
    hue="y",
    palette=sns.color_palette("hls", 10),
    data=df,
    legend="full",
    alpha=0.3
)

pca_50 = PCA(n_components=50)
pca_result_50 = pca_50.fit_transform(x_train_flatten)
print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))

x_train_flatten.shape, y_train_flatten.shape, pca_result_50.shape

tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(pca_result_50)

plt.figure(figsize=(16,10))
sns.scatterplot(
    x=tsne_results[:,0], y=tsne_results[:,1],
    hue="y",
    palette=sns.color_palette("hls", 10),
    data=df,
    legend="full",
    alpha=0.3
)

"""Now, you will perform the same exercise on cifar10 or cifar100."""

# your code goes here
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from tensorflow.keras.datasets import cifar10

# Load CIFAR-10 data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Normalize the data
x_train = x_train / 255.0
x_test = x_test / 255.0

# Flatten the images for PCA
x_train_flatten = x_train.reshape(x_train.shape[0], -1) # Reshape from (50000, 32, 32, 3) to (50000, 3072)
x_test_flatten = x_test.reshape(x_test.shape[0], -1) # Reshape for consistency

# Applying PCA to reduce dimensions to 3 for visualization
pca = PCA(n_components=3)
pca_result = pca.fit_transform(x_train_flatten)

# Visualize the PCA result
fig = plt.figure(figsize=(16,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(
    xs=pca_result[:,0],
    ys=pca_result[:,1],
    zs=pca_result[:,2],
    c=y_train.flatten(),
    cmap='tab10', # Color map for 10 classes
    marker='o' # Marker style
)
ax.set_xlabel('PCA 1')
ax.set_ylabel('PCA 2')
ax.set_zlabel('PCA 3')
plt.show()

import time
import pandas as pd
import seaborn as sns

# Use only 3000 samples to speed up the process
x_train_flatten = x_train_flatten[:3000]
y_train_flatten = y_train.flatten()[:3000]

# Apply t-SNE
time_start = time.time()
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(x_train_flatten)
print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))

# Prepare the data for seaborn plot
data = {"x": tsne_results[:,0], "y": tsne_results[:,1], "label": y_train_flatten}
df = pd.DataFrame(data)

# Plot with seaborn
plt.figure(figsize=(16,10))
sns.scatterplot(
    x="x", y="y",
    hue="label",
    palette=sns.color_palette("hls", 10),
    data=df,
    legend="full",
    alpha=0.3
)
plt.show()

pca_50 = PCA(n_components=50)
pca_result_50 = pca_50.fit_transform(x_train_flatten)
print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))

print(x_train_flatten.shape, y_train_flatten.shape, pca_result_50.shape)
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(pca_result_50)

plt.figure(figsize=(16,10))
sns.scatterplot(
    x=tsne_results[:,0], y=tsne_results[:,1],
    hue="y",
    palette=sns.color_palette("hls", 10),
    data=df,
    legend="full",
    alpha=0.3
)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from tensorflow.keras.datasets import cifar100

# Load CIFAR-100 data
(x_train, y_train), (x_test, y_test) = cifar100.load_data()

# Normalize the data
x_train = x_train / 255.0
x_test = x_test / 255.0

# Flatten the images for PCA
x_train_flatten = x_train.reshape(x_train.shape[0], -1)  # Reshape from (50000, 32, 32, 3) to (50000, 3072)
x_test_flatten = x_test.reshape(x_test.shape[0], -1)    # Reshape for consistency

# Applying PCA to reduce dimensions to 3 for visualization
pca = PCA(n_components=3)
pca_result = pca.fit_transform(x_train_flatten)

# Visualize the PCA result
fig = plt.figure(figsize=(16,10))
ax = fig.add_subplot(111, projection='3d')
sc = ax.scatter(
    xs=pca_result[:,0],
    ys=pca_result[:,1],
    zs=pca_result[:,2],
    c=y_train.flatten(),
    cmap='viridis',  # A colormap that can better handle 100 classes; adjust as needed
    marker='o'
)
ax.set_xlabel('PCA 1')
ax.set_ylabel('PCA 2')
ax.set_zlabel('PCA 3')

# Adding a color bar to represent different classes
plt.colorbar(sc)

plt.show()

x_train_flatten = x_train_flatten[:3000]
y_train_flatten = y_train.flatten()[:3000]

# Apply t-SNE
time_start = time.time()
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(x_train_flatten)
print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))

# Prepare the data for seaborn plot
data = {"x": tsne_results[:,0], "y": tsne_results[:,1], "label": y_train_flatten}
df = pd.DataFrame(data)

# Plot with seaborn
plt.figure(figsize=(16,10))
sns.scatterplot(
    x="x", y="y",
    hue="label",
    palette=sns.color_palette("hls", 10),
    data=df,
    legend="full",
    alpha=0.3
)
plt.show()

pca_50 = PCA(n_components=50)
pca_result_50 = pca_50.fit_transform(x_train_flatten)
print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))

print(x_train_flatten.shape, y_train_flatten.shape, pca_result_50.shape)

tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(pca_result_50)
# Prepare the data for seaborn plot
data = {"x": tsne_results[:,0], "y": tsne_results[:,1], "label": y_train_flatten}
df = pd.DataFrame(data)

plt.figure(figsize=(16,10))
sns.scatterplot(
    x=tsne_results[:,0], y=tsne_results[:,1],
    hue="y",
    palette=sns.color_palette("hls", 10),
    data=df,
    legend="full",
    alpha=0.3
)

"""With the help of ChatGPT, explain the difference among PCA (SVD if you remove mean(x) and compute np.dot(X.T, X) to create a square matrix), tSNE and UMAP, explaining how it works.  I will be checking if you left ChatGPT generating the sentences and it ended up writing garbage.

The request to differentiate among PCA (with a focus on its relation to SVD), t-SNE, and UMAP requires an understanding of each method's underlying principles and how they work to reduce dimensionality or visualize high-dimensional data. Let's break down each method to provide a clear and accurate explanation.
PCA (Principal Component Analysis)

    How it Works: PCA seeks to reduce the dimensionality of data by identifying the directions (principal components) that maximize variance. The steps involve centering the data by subtracting the mean (to make the data zero-centered) and then computing the covariance matrix. An alternative approach is to use Singular Value Decomposition (SVD) on the centered data matrix XX. If you perform SVD after removing the mean from XX and then compute np.dot(XT,X)np.dot(XT,X), you effectively obtain the covariance matrix, which PCA decomposes to find the principal components. The principal components are the eigenvectors of the covariance matrix, and they form a new basis for the data with maximized variance.

    Key Points: PCA is linear and focuses on orthogonal transformation. It's effective for linear data distributions and where the goal is to preserve global data structure and variance.

t-SNE (t-Distributed Stochastic Neighbor Embedding)

    How it Works: t-SNE is a nonlinear technique primarily used for data visualization. It converts the high-dimensional Euclidean distances between data points into conditional probabilities that represent similarities. The similarity of datapoint xjxj​ to datapoint xixi​ is the probability pj∣ipj∣i​ that xixi​ would pick xjxj​ as its neighbor if neighbors were picked in proportion to their probability density under a Gaussian centered at xixi​. t-SNE aims to minimize the divergence between these conditional probabilities in the high-dimensional space and the corresponding probabilities in the low-dimensional space, using a gradient descent method. The "t" in t-SNE refers to the t-distribution used in the low-dimensional space to alleviate the crowding problem and allow for a more manageable visualization of clusters.

    Key Points: t-SNE is highly effective for creating visually appealing representations of high-dimensional data. It excels in preserving local structures and revealing clusters at many scales but can be computationally intensive and sensitive to hyperparameters.

UMAP (Uniform Manifold Approximation and Projection)

    How it Works: UMAP, like t-SNE, is a nonlinear dimension reduction technique but operates under a slightly different mathematical framework. It begins by constructing a high-dimensional graph representing the manifold of the data, where each point is connected to its nearest neighbors. Then, it seeks a low-dimensional graph that best preserves this topological structure. UMAP uses a fuzzy simplicial set approach to model the high-dimensional data's geometric structure and then optimizes the layout of data in the lower-dimensional space to reflect this structure as closely as possible.

    Key Points: UMAP is praised for its speed and ability to maintain both local and more of the global data structure compared to t-SNE. It's also versatile, being applicable beyond just visualization to general dimension reduction tasks. UMAP tends to be more scalable and can handle larger datasets more efficiently than t-SNE.

Summary

    PCA (and SVD): Linear, focuses on variance maximization, and preserves global structure. It's straightforward and computationally efficient but may not capture nonlinear relationships.
    t-SNE: Nonlinear, excels in preserving local data structures and revealing clusters, ideal for visualization. However, it's computationally expensive and sensitive to hyperparameters.
    UMAP: Nonlinear, balances the preservation of local and global structures, and is more computationally efficient than t-SNE, making it suitable for both dimension reduction and visualization across larger datasets.

Each method has its unique advantages and applications, with the choice among them depending on the specific goals of the dimensionality reduction task, such as whether the focus is on visualization, data compression, or noise reduction.
"""